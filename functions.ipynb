{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score,\\\n",
    "    recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for tracking experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty df for storing results\n",
    "test_results = pd.DataFrame(columns=['model_name',\n",
    "                                'model_params',\n",
    "                                'data_desc',\n",
    "                                'f1',\n",
    "                                'acc',\n",
    "                                'recall',\n",
    "                                'prec',\n",
    "                                'cf_matrix',\n",
    "                                'exec_time',\n",
    "                                'notes'])\n",
    "\n",
    "def eval_model(model_name, model_params, data_desc, exec_time,\n",
    "               y_test, y_pred, notes=''):\n",
    "    '''\n",
    "    eval_model(model_name, model_params, data_desc, exec_time,\n",
    "               y_test, y_pred, notes='')\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_name: name of model\n",
    "    model_params: dict of (hyper)parameters passed to model\n",
    "    data_desc: description of dataset (preprocessing steps etc.)\n",
    "    exec_time: execution time\n",
    "    y_test: real test labels\n",
    "    y_pred: predicted test labels\n",
    "    notes: additional notes (default: empty string)\n",
    "    '''\n",
    "\n",
    "    result = {'model_name': model_name,\n",
    "              'model_params': model_params,\n",
    "              'data_desc': data_desc,\n",
    "              'f1': round(f1_score(y_test, y_pred), 5),\n",
    "              'acc': round(accuracy_score(y_test, y_pred), 5),\n",
    "              'recall': round(recall_score(y_test, y_pred), 5),\n",
    "              'prec': round(precision_score(y_test, y_pred), 5),\n",
    "              'cf_matrix': confusion_matrix(y_test, y_pred),\n",
    "              'exec_time': exec_time,\n",
    "              'notes': notes}\n",
    "    \n",
    "    test_results.loc[len(test_results)] = result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
