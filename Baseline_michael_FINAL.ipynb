{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ChnD36qHhuy"
      },
      "source": [
        "# Baseline model on final data (Michael)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLTUtsD6HupB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nisbn3mTG0fj",
        "outputId": "c3a65a47-0bea-4de2-c594-1b5ca57dec48"
      },
      "outputs": [],
      "source": [
        "# import the usual suspects / basics\n",
        "import time; full_run_time_start = time.time() # start timing exec right away\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from scipy import sparse\n",
        "import re\n",
        "import os\n",
        "\n",
        "# scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, classification_report, f1_score,\\\n",
        "    accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# display all df columns (default is 20)\n",
        "pd.options.display.max_columns = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility functions for testing models and tracking results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# empty df for storing results\n",
        "test_results = pd.DataFrame(columns=['model_name',\n",
        "                                'model_params',\n",
        "                                'data_desc',\n",
        "                                'data_size',\n",
        "                                'features_no',\n",
        "                                'f1',\n",
        "                                'acc',\n",
        "                                'recall',\n",
        "                                'prec',\n",
        "                                'roc_auc',\n",
        "                                'cf_matrix',\n",
        "                                'train_time',\n",
        "                                'notes'])\n",
        "\n",
        "def test_model(model, model_name, model_params, data_desc, X, y, notes=''):\n",
        "    '''\n",
        "    test_model(model, model_params, data_desc, X, y, notes='')\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    model: instance of model to test\n",
        "    model_name: name of model\n",
        "    model_params: dict of (hyper)parameters passed to model\n",
        "    data_desc: description of dataset (preprocessing steps etc.)\n",
        "    X: feature array \n",
        "    y: target/label array\n",
        "    notes: additional notes (default: empty string)\n",
        "    '''\n",
        "\n",
        "    # Split data using default of 75% for train, 25% for test.\n",
        "    # Make sure test data has same toxic/nontoxic ratio as train data by\n",
        "    # using stratify parameter.\n",
        "    X_train, X_test, y_train, y_test =\\\n",
        "        train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "    \n",
        "    # train model and time execution\n",
        "    train_time_start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_time = time.time() - train_time_start\n",
        "    train_time_str = f'{int(train_time // 60)}m {round(train_time % 60)}s'\n",
        "\n",
        "    # Make predictions on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "    return {'model_name': model_name,\n",
        "            'model_params': model_params,\n",
        "            'data_desc': data_desc,\n",
        "            'data_size': X.shape[0],\n",
        "            'features_no': X.shape[1],\n",
        "            'f1': round(f1_score(y_test, y_pred), 5),\n",
        "            'acc': round(accuracy_score(y_test, y_pred), 5),\n",
        "            'recall': round(recall_score(y_test, y_pred), 5),\n",
        "            'prec': round(precision_score(y_test, y_pred), 5),\n",
        "            'roc_auc': round(roc_auc_score(y_test, y_pred_proba), 5),\n",
        "            'cf_matrix': confusion_matrix(y_test, y_pred),\n",
        "            'train_time': train_time_str,\n",
        "            'notes': notes}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store_test_result(result):\n",
        "    test_results.loc[len(test_results)] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MP847vfIJMN"
      },
      "source": [
        "## Load data (final data file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r6YNY0NIIL4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(447998, 44)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data/merged_data.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['toxic'] = df['toxicity'] >= 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_new = df[['comment_text', 'toxic']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OH yes - Were those evil Christian Missionarie...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is this black racist crap still on the G&amp;M...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>even up here.......BLACKS!</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Blame men.  There's always an excuse to blame ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>And the woman exposing herself saying grab thi...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447993</th>\n",
              "      <td>Another man shamming article. If white men did...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447994</th>\n",
              "      <td>\"no matter what is put in front of you regardi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447995</th>\n",
              "      <td>The Democrat party aided and abetted by it's M...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447996</th>\n",
              "      <td>I just don't find her a very good representati...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447997</th>\n",
              "      <td>You know the Trump fanatics are trolling the G...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>447998 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment_text  toxic\n",
              "0       OH yes - Were those evil Christian Missionarie...   True\n",
              "1       Why is this black racist crap still on the G&M...   True\n",
              "2                              even up here.......BLACKS!   True\n",
              "3       Blame men.  There's always an excuse to blame ...   True\n",
              "4       And the woman exposing herself saying grab thi...   True\n",
              "...                                                   ...    ...\n",
              "447993  Another man shamming article. If white men did...  False\n",
              "447994  \"no matter what is put in front of you regardi...  False\n",
              "447995  The Democrat party aided and abetted by it's M...  False\n",
              "447996  I just don't find her a very good representati...  False\n",
              "447997  You know the Trump fanatics are trolling the G...  False\n",
              "\n",
              "[447998 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 447998 entries, 0 to 447997\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   comment_text  447998 non-null  object\n",
            " 1   toxic         447998 non-null  bool  \n",
            "dtypes: bool(1), object(1)\n",
            "memory usage: 3.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df_new.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking for NaN's ...\n",
            "comment_text    0\n",
            "toxic           0\n",
            "dtype: int64\n",
            "\n",
            "Rows before dropping: 447998\n",
            "Rows after: 447998\n",
            "Rows dropped: 0\n"
          ]
        }
      ],
      "source": [
        "print('Checking for NaN\\'s ...')\n",
        "print(df.isna().sum())\n",
        "rows_before = df.shape[0]\n",
        "print(\"\\nRows before dropping:\", rows_before)\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "rows_after = df.shape[0]\n",
        "print('Rows after:', rows_after)\n",
        "print('Rows dropped:', rows_before - rows_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lZffM2npRCPf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OH yes - Were those evil Christian Missionarie...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is this black racist crap still on the G&amp;M...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>even up here.......BLACKS!</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Blame men.  There's always an excuse to blame ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>And the woman exposing herself saying grab thi...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        comment_text  toxic\n",
              "0  OH yes - Were those evil Christian Missionarie...   True\n",
              "1  Why is this black racist crap still on the G&M...   True\n",
              "2                         even up here.......BLACKS!   True\n",
              "3  Blame men.  There's always an excuse to blame ...   True\n",
              "4  And the woman exposing herself saying grab thi...   True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Create smaller sample from data to speed up experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using full data (447998 rows).\n"
          ]
        }
      ],
      "source": [
        "sample_size = None\n",
        "\n",
        "# uncomment to create sample of desired size\n",
        "#sample_size = 50_000\n",
        "\n",
        "if sample_size != None:\n",
        "    # ratio toxic/nontoxic\n",
        "    tox_perc = 0.4\n",
        "    nontox_perc = 0.6\n",
        "\n",
        "    # number of toxic/nontoxic rows\n",
        "    sample_size_tox = int(sample_size * tox_perc)\n",
        "    sample_size_nontox = int(sample_size * nontox_perc)\n",
        "\n",
        "    sample_tox = df[df['toxic'] == 1].sample(sample_size_tox,\n",
        "                                             random_state=42)\n",
        "    sample_nontox = df[df['toxic'] == 0].sample(sample_size_nontox,\n",
        "                                                random_state=42)\n",
        "\n",
        "    df = pd.concat([sample_tox, sample_nontox])\n",
        "    print(f'Using sample ({df.shape[0]} rows).')\n",
        "\n",
        "else:\n",
        "    print(f'Using full data ({df.shape[0]} rows).')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create label/target variable and check for imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "29jE5PSrPFE2"
      },
      "outputs": [],
      "source": [
        "target = df['toxic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nontoxic (0): 397204 (88.7 %)\n",
            "Toxic (1): 50794 (11.3 %)\n"
          ]
        }
      ],
      "source": [
        "value_counts = target.value_counts()\n",
        "nontoxic_count = value_counts[0]\n",
        "toxic_count = value_counts[1]\n",
        "nontoxic_perc =\\\n",
        "    round((nontoxic_count / (nontoxic_count + toxic_count)) * 100, 1)\n",
        "toxic_perc =\\\n",
        "    round((toxic_count / (nontoxic_count + toxic_count)) * 100, 1)\n",
        "\n",
        "print(f'Nontoxic (0): {nontoxic_count} ({nontoxic_perc} %)')\n",
        "print(f'Toxic (1): {toxic_count} ({toxic_perc} %)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function for bag of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bow(data):\n",
        "    vect = CountVectorizer()\n",
        "    return vect.fit_transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run baseline model (logistic regression) on different data cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'max_iter': 2_000}\n",
        "\n",
        "# load model with parameters\n",
        "lr = LogisticRegression(**params)\n",
        "\n",
        "test_result = test_model(lr, 'BASELINE (logistic regression)', params,\n",
        "                    'bag of words on col \"comment_text\"', bow(df['comment_text']), target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show test results + total exec time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>model_params</th>\n",
              "      <th>data_desc</th>\n",
              "      <th>data_size</th>\n",
              "      <th>features_no</th>\n",
              "      <th>f1</th>\n",
              "      <th>acc</th>\n",
              "      <th>recall</th>\n",
              "      <th>prec</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>cf_matrix</th>\n",
              "      <th>train_time</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BASELINE (logistic regression)</td>\n",
              "      <td>{'max_iter': 2000}</td>\n",
              "      <td>bag of words on col \"comment_text\"</td>\n",
              "      <td>447998</td>\n",
              "      <td>162553</td>\n",
              "      <td>0.53912</td>\n",
              "      <td>0.91407</td>\n",
              "      <td>0.44325</td>\n",
              "      <td>0.6879</td>\n",
              "      <td>0.88588</td>\n",
              "      <td>[[77398, 2043], [5656, 4503]]</td>\n",
              "      <td>1m 2s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       model_name        model_params  \\\n",
              "0  BASELINE (logistic regression)  {'max_iter': 2000}   \n",
              "\n",
              "                            data_desc  data_size  features_no       f1  \\\n",
              "0  bag of words on col \"comment_text\"     447998       162553  0.53912   \n",
              "\n",
              "       acc   recall    prec  roc_auc                      cf_matrix  \\\n",
              "0  0.91407  0.44325  0.6879  0.88588  [[77398, 2043], [5656, 4503]]   \n",
              "\n",
              "  train_time notes  \n",
              "0      1m 2s        "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full run time: 1m 15s\n"
          ]
        }
      ],
      "source": [
        "full_run_time = time.time() - full_run_time_start\n",
        "print(f'Full run time: {int(full_run_time // 60)}m {round(full_run_time % 60)}s')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
