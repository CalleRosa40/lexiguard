{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ChnD36qHhuy"
      },
      "source": [
        "# XGBoost experiments (Michael)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLTUtsD6HupB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nisbn3mTG0fj",
        "outputId": "c3a65a47-0bea-4de2-c594-1b5ca57dec48"
      },
      "outputs": [],
      "source": [
        "# import the usual suspects / basics\n",
        "import time; full_run_time_start = time.time() # start timing exec right away\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from scipy import sparse\n",
        "import re\n",
        "\n",
        "# scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, classification_report, f1_score,\\\n",
        "    accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# currently not used and thus commented out\n",
        "# import nltk\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('omw-1.4')\n",
        "\n",
        "# display all df columns (default is 20)\n",
        "pd.options.display.max_columns = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility function for testing models and tracking results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# empty df for storing results\n",
        "test_results = pd.DataFrame(columns=['model_name',\n",
        "                                'model_params',\n",
        "                                'data_desc',\n",
        "                                'data_size',\n",
        "                                'features_no',\n",
        "                                'f1',\n",
        "                                'acc',\n",
        "                                'recall',\n",
        "                                'prec',\n",
        "                                'roc_auc',\n",
        "                                'cf_matrix',\n",
        "                                'train_time',\n",
        "                                'notes'])\n",
        "\n",
        "def test_model(model, model_name, model_params, data_desc, X, y, notes=''):\n",
        "    '''\n",
        "    test_model(model, model_params, data_desc, X, y, notes='')\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    model: instance of model to test\n",
        "    model_name: name of model\n",
        "    model_params: dict of (hyper)parameters passed to model\n",
        "    data_desc: description of dataset (preprocessing steps etc.)\n",
        "    X: feature array \n",
        "    y: target/label array\n",
        "    notes: additional notes (default: empty string)\n",
        "    '''\n",
        "\n",
        "    # Split data using default of 75% for train, 25% for test.\n",
        "    # Make sure test data has same toxic/nontoxic ratio as train data by\n",
        "    # using stratify parameter.\n",
        "    X_train, X_test, y_train, y_test =\\\n",
        "        train_test_split(X, y, stratify=y, random_state=42)\n",
        "    \n",
        "    # train model and time execution\n",
        "    train_time_start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_time = time.time() - train_time_start\n",
        "    train_time_str = f'{int(train_time // 60)}m {round(train_time % 60)}s'\n",
        "\n",
        "    # Make predictions on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "    return {'model_name': model_name,\n",
        "            'model_params': model_params,\n",
        "            'data_desc': data_desc,\n",
        "            'data_size': X.shape[0],\n",
        "            'features_no': X.shape[1],\n",
        "            'f1': round(f1_score(y_test, y_pred), 3),\n",
        "            'acc': round(accuracy_score(y_test, y_pred), 3),\n",
        "            'recall': round(recall_score(y_test, y_pred), 3),\n",
        "            'prec': round(precision_score(y_test, y_pred), 3),\n",
        "            'roc_auc': round(roc_auc_score(y_test, y_pred_proba), 3),\n",
        "            'cf_matrix': confusion_matrix(y_test, y_pred),\n",
        "            'train_time': train_time_str,\n",
        "            'notes': notes}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store_test_result(result):\n",
        "    test_results.loc[len(test_results)] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MP847vfIJMN"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r6YNY0NIIL4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(360038, 5)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# new cleaned data\n",
        "df = pd.read_csv('data/data_usampl_60_40_comments_cleaned_preproc_fasttext.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Create smaller sample from data to speed up experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using sample (50000 rows).\n"
          ]
        }
      ],
      "source": [
        "sample_size = None\n",
        "\n",
        "# uncomment to create sample of desired size\n",
        "sample_size = 50_000\n",
        "\n",
        "if sample_size != None:\n",
        "    # ratio toxic/nontoxic\n",
        "    tox_perc = 0.4\n",
        "    nontox_perc = 0.6\n",
        "\n",
        "    # number of toxic/nontoxic rows\n",
        "    sample_size_tox = int(sample_size * tox_perc)\n",
        "    sample_size_nontox = int(sample_size * nontox_perc)\n",
        "\n",
        "    sample_tox = df[df['toxic'] == 1].sample(sample_size_tox,\n",
        "                                             random_state=42)\n",
        "    sample_nontox = df[df['toxic'] == 0].sample(sample_size_nontox,\n",
        "                                                random_state=42)\n",
        "\n",
        "    df = pd.concat([sample_tox, sample_nontox])\n",
        "    print(f'Using sample ({df.shape[0]} rows).')\n",
        "\n",
        "else:\n",
        "    print(f'Using full data ({df.shape[0]} rows).')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop rows with NaN's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rows with NaN's before dropping: 50000\n",
            "rows after: 50000\n",
            "rows dropped: 0\n"
          ]
        }
      ],
      "source": [
        "rows_before = df.shape[0]\n",
        "print(\"rows with NaN's before dropping:\", df.shape[0])\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "print('rows after:', df.shape[0])\n",
        "print('rows dropped:', rows_before - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IbUc5bP0IUIS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 5 columns):\n",
            " #   Column                 Non-Null Count  Dtype \n",
            "---  ------                 --------------  ----- \n",
            " 0   comment_raw            50000 non-null  object\n",
            " 1   comment_clean          50000 non-null  object\n",
            " 2   comment_clean_preproc  50000 non-null  object\n",
            " 3   ft_vector              50000 non-null  object\n",
            " 4   toxic                  50000 non-null  int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 1.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lZffM2npRCPf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_raw</th>\n",
              "      <th>comment_clean</th>\n",
              "      <th>comment_clean_preproc</th>\n",
              "      <th>ft_vector</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good.  Let's hope the president listens to his...</td>\n",
              "      <td>Good. Let's hope the president listens to his ...</td>\n",
              "      <td>good let hope president listen adviser instead...</td>\n",
              "      <td>[ 4.41469215e-02 -1.07265105e-02 -2.13325340e-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actually I'd consider people like Lindsey cons...</td>\n",
              "      <td>Actually I'd consider people like Lindsey cons...</td>\n",
              "      <td>actually consider people like Lindsey conserva...</td>\n",
              "      <td>[ 0.04503527  0.01501187 -0.03122971  0.095336...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Once again the left proves they are the scum o...</td>\n",
              "      <td>Once again the left proves they are the scum o...</td>\n",
              "      <td>left prove scum Earth win election spend time ...</td>\n",
              "      <td>[ 3.61347646e-02  6.09276891e-02 -4.58316170e-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>And Trump should be fired if his tweets are in...</td>\n",
              "      <td>And Trump should be fired if his tweets are in...</td>\n",
              "      <td>Trump fire tweet insensitive childish demente</td>\n",
              "      <td>[ 0.03957259  0.15793295 -0.02021416  0.057683...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Making decisions based on factors as nebulous ...</td>\n",
              "      <td>Making decisions based on factors as nebulous ...</td>\n",
              "      <td>make decision base factor nebulous Paris Accor...</td>\n",
              "      <td>[ 0.0471274   0.01432506 -0.06455102  0.083196...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I couldn't disagree more\\n\\nThe positions are ...</td>\n",
              "      <td>I couldn't disagree more The positions are ent...</td>\n",
              "      <td>disagree position entirely consistent long und...</td>\n",
              "      <td>[ 0.07299212  0.06142109 -0.07250728  0.154581...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Just so RG readers know, the author of this sp...</td>\n",
              "      <td>Just so RG readers know, the author of this sp...</td>\n",
              "      <td>RG reader know author spiel guy name Michael B...</td>\n",
              "      <td>[-0.00407603  0.05170771 -0.03713477  0.124179...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>If anyone is interested. WalMart on W11th no l...</td>\n",
              "      <td>If anyone is interested. WalMart on W_number_t...</td>\n",
              "      <td>interested WalMart W_number_th long charge bag...</td>\n",
              "      <td>[-0.01897589 -0.0200948  -0.06883522  0.006006...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>Pierre Trudeau rode around Montreal on his bik...</td>\n",
              "      <td>Pierre Trudeau rode around Montreal on his bik...</td>\n",
              "      <td>Pierre Trudeau ride Montreal bike dress Nazi r...</td>\n",
              "      <td>[ 1.02514643e-02 -1.37367821e-03 -3.53123546e-...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>We don't really even care anymore, Trumpykins....</td>\n",
              "      <td>We don't really even care anymore, Trumpykins....</td>\n",
              "      <td>care anymore trumpykin build WALL go pay Slain...</td>\n",
              "      <td>[ 0.01356251 -0.02596289  0.00971039  0.028168...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment_raw  \\\n",
              "0      Good.  Let's hope the president listens to his...   \n",
              "1      Actually I'd consider people like Lindsey cons...   \n",
              "2      Once again the left proves they are the scum o...   \n",
              "3      And Trump should be fired if his tweets are in...   \n",
              "4      Making decisions based on factors as nebulous ...   \n",
              "...                                                  ...   \n",
              "49995  I couldn't disagree more\\n\\nThe positions are ...   \n",
              "49996  Just so RG readers know, the author of this sp...   \n",
              "49997  If anyone is interested. WalMart on W11th no l...   \n",
              "49998  Pierre Trudeau rode around Montreal on his bik...   \n",
              "49999  We don't really even care anymore, Trumpykins....   \n",
              "\n",
              "                                           comment_clean  \\\n",
              "0      Good. Let's hope the president listens to his ...   \n",
              "1      Actually I'd consider people like Lindsey cons...   \n",
              "2      Once again the left proves they are the scum o...   \n",
              "3      And Trump should be fired if his tweets are in...   \n",
              "4      Making decisions based on factors as nebulous ...   \n",
              "...                                                  ...   \n",
              "49995  I couldn't disagree more The positions are ent...   \n",
              "49996  Just so RG readers know, the author of this sp...   \n",
              "49997  If anyone is interested. WalMart on W_number_t...   \n",
              "49998  Pierre Trudeau rode around Montreal on his bik...   \n",
              "49999  We don't really even care anymore, Trumpykins....   \n",
              "\n",
              "                                   comment_clean_preproc  \\\n",
              "0      good let hope president listen adviser instead...   \n",
              "1      actually consider people like Lindsey conserva...   \n",
              "2      left prove scum Earth win election spend time ...   \n",
              "3          Trump fire tweet insensitive childish demente   \n",
              "4      make decision base factor nebulous Paris Accor...   \n",
              "...                                                  ...   \n",
              "49995  disagree position entirely consistent long und...   \n",
              "49996  RG reader know author spiel guy name Michael B...   \n",
              "49997  interested WalMart W_number_th long charge bag...   \n",
              "49998  Pierre Trudeau ride Montreal bike dress Nazi r...   \n",
              "49999  care anymore trumpykin build WALL go pay Slain...   \n",
              "\n",
              "                                               ft_vector  toxic  \n",
              "0      [ 4.41469215e-02 -1.07265105e-02 -2.13325340e-...      1  \n",
              "1      [ 0.04503527  0.01501187 -0.03122971  0.095336...      1  \n",
              "2      [ 3.61347646e-02  6.09276891e-02 -4.58316170e-...      1  \n",
              "3      [ 0.03957259  0.15793295 -0.02021416  0.057683...      1  \n",
              "4      [ 0.0471274   0.01432506 -0.06455102  0.083196...      1  \n",
              "...                                                  ...    ...  \n",
              "49995  [ 0.07299212  0.06142109 -0.07250728  0.154581...      0  \n",
              "49996  [-0.00407603  0.05170771 -0.03713477  0.124179...      0  \n",
              "49997  [-0.01897589 -0.0200948  -0.06883522  0.006006...      0  \n",
              "49998  [ 1.02514643e-02 -1.37367821e-03 -3.53123546e-...      0  \n",
              "49999  [ 0.01356251 -0.02596289  0.00971039  0.028168...      0  \n",
              "\n",
              "[50000 rows x 5 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create label/target variable and check for imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "29jE5PSrPFE2"
      },
      "outputs": [],
      "source": [
        "target = df['toxic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nontoxic (0): 30000 (60.0 %)\n",
            "Toxic (1): 20000 (40.0 %)\n"
          ]
        }
      ],
      "source": [
        "value_counts = target.value_counts()\n",
        "nontoxic_count = value_counts[0]\n",
        "toxic_count = value_counts[1]\n",
        "nontoxic_perc =\\\n",
        "    round((nontoxic_count / (nontoxic_count + toxic_count)) * 100, 1)\n",
        "toxic_perc =\\\n",
        "    round((toxic_count / (nontoxic_count + toxic_count)) * 100, 1)\n",
        "\n",
        "print(f'Nontoxic (0): {nontoxic_count} ({nontoxic_perc} %)')\n",
        "print(f'Toxic (1): {toxic_count} ({toxic_perc} %)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create various corpora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Raw corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corp_raw = df['comment_raw']\n",
        "corp_raw.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleaned corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corp_clean = df['comment_clean']\n",
        "corp_clean.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pre-processed corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corp_pp = df['comment_clean_preproc']\n",
        "corp_pp.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Corpus of fastText vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.044147</td>\n",
              "      <td>-0.010727</td>\n",
              "      <td>-0.021333</td>\n",
              "      <td>0.073693</td>\n",
              "      <td>-0.021842</td>\n",
              "      <td>0.106237</td>\n",
              "      <td>0.048300</td>\n",
              "      <td>-0.033911</td>\n",
              "      <td>-0.003105</td>\n",
              "      <td>-0.029260</td>\n",
              "      <td>-0.017412</td>\n",
              "      <td>0.018268</td>\n",
              "      <td>-0.012076</td>\n",
              "      <td>0.004286</td>\n",
              "      <td>0.062145</td>\n",
              "      <td>0.006855</td>\n",
              "      <td>0.022881</td>\n",
              "      <td>-0.024971</td>\n",
              "      <td>0.006245</td>\n",
              "      <td>0.002184</td>\n",
              "      <td>-0.071574</td>\n",
              "      <td>0.051942</td>\n",
              "      <td>-0.000050</td>\n",
              "      <td>0.017572</td>\n",
              "      <td>0.010189</td>\n",
              "      <td>-0.026628</td>\n",
              "      <td>-0.092220</td>\n",
              "      <td>0.018010</td>\n",
              "      <td>0.074499</td>\n",
              "      <td>0.021300</td>\n",
              "      <td>0.075879</td>\n",
              "      <td>0.048802</td>\n",
              "      <td>-0.143237</td>\n",
              "      <td>-0.148499</td>\n",
              "      <td>-0.035969</td>\n",
              "      <td>0.028878</td>\n",
              "      <td>-0.059840</td>\n",
              "      <td>-0.137513</td>\n",
              "      <td>0.002799</td>\n",
              "      <td>-0.057196</td>\n",
              "      <td>-0.001409</td>\n",
              "      <td>0.055020</td>\n",
              "      <td>0.102742</td>\n",
              "      <td>-0.117058</td>\n",
              "      <td>0.157518</td>\n",
              "      <td>0.094997</td>\n",
              "      <td>-0.007800</td>\n",
              "      <td>0.034279</td>\n",
              "      <td>-0.063406</td>\n",
              "      <td>-0.064017</td>\n",
              "      <td>-0.016375</td>\n",
              "      <td>0.014664</td>\n",
              "      <td>-0.050131</td>\n",
              "      <td>0.099417</td>\n",
              "      <td>-0.006343</td>\n",
              "      <td>-0.066297</td>\n",
              "      <td>0.051177</td>\n",
              "      <td>0.183496</td>\n",
              "      <td>-0.063202</td>\n",
              "      <td>0.009117</td>\n",
              "      <td>-0.053415</td>\n",
              "      <td>0.044517</td>\n",
              "      <td>0.013730</td>\n",
              "      <td>0.011338</td>\n",
              "      <td>0.013443</td>\n",
              "      <td>-0.104968</td>\n",
              "      <td>0.002170</td>\n",
              "      <td>0.009175</td>\n",
              "      <td>0.074044</td>\n",
              "      <td>0.016404</td>\n",
              "      <td>0.009218</td>\n",
              "      <td>-0.003867</td>\n",
              "      <td>0.013765</td>\n",
              "      <td>0.056818</td>\n",
              "      <td>0.130176</td>\n",
              "      <td>-0.050709</td>\n",
              "      <td>-0.108570</td>\n",
              "      <td>0.132067</td>\n",
              "      <td>-0.052417</td>\n",
              "      <td>-0.002704</td>\n",
              "      <td>0.084048</td>\n",
              "      <td>0.018089</td>\n",
              "      <td>0.015692</td>\n",
              "      <td>0.109482</td>\n",
              "      <td>0.058689</td>\n",
              "      <td>0.019810</td>\n",
              "      <td>0.011112</td>\n",
              "      <td>0.046629</td>\n",
              "      <td>0.097933</td>\n",
              "      <td>0.038506</td>\n",
              "      <td>0.144735</td>\n",
              "      <td>0.017034</td>\n",
              "      <td>0.050863</td>\n",
              "      <td>0.090643</td>\n",
              "      <td>0.037196</td>\n",
              "      <td>-0.060164</td>\n",
              "      <td>-0.204394</td>\n",
              "      <td>0.036898</td>\n",
              "      <td>0.005015</td>\n",
              "      <td>-0.080517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.045035</td>\n",
              "      <td>0.015012</td>\n",
              "      <td>-0.031230</td>\n",
              "      <td>0.095337</td>\n",
              "      <td>-0.005714</td>\n",
              "      <td>0.072040</td>\n",
              "      <td>0.021957</td>\n",
              "      <td>-0.104118</td>\n",
              "      <td>-0.012181</td>\n",
              "      <td>-0.034687</td>\n",
              "      <td>-0.009410</td>\n",
              "      <td>0.018831</td>\n",
              "      <td>-0.037818</td>\n",
              "      <td>-0.007835</td>\n",
              "      <td>0.026300</td>\n",
              "      <td>0.040378</td>\n",
              "      <td>0.045364</td>\n",
              "      <td>-0.009003</td>\n",
              "      <td>0.017358</td>\n",
              "      <td>0.044997</td>\n",
              "      <td>-0.033400</td>\n",
              "      <td>0.055305</td>\n",
              "      <td>-0.014680</td>\n",
              "      <td>0.035894</td>\n",
              "      <td>0.005406</td>\n",
              "      <td>-0.064536</td>\n",
              "      <td>-0.022109</td>\n",
              "      <td>0.004644</td>\n",
              "      <td>0.065064</td>\n",
              "      <td>-0.003331</td>\n",
              "      <td>0.078107</td>\n",
              "      <td>0.064094</td>\n",
              "      <td>-0.087262</td>\n",
              "      <td>-0.071299</td>\n",
              "      <td>-0.013654</td>\n",
              "      <td>0.003943</td>\n",
              "      <td>0.009838</td>\n",
              "      <td>-0.122297</td>\n",
              "      <td>0.017988</td>\n",
              "      <td>-0.051111</td>\n",
              "      <td>0.042570</td>\n",
              "      <td>0.038836</td>\n",
              "      <td>0.092849</td>\n",
              "      <td>-0.126283</td>\n",
              "      <td>0.115054</td>\n",
              "      <td>0.119809</td>\n",
              "      <td>-0.031324</td>\n",
              "      <td>-0.015771</td>\n",
              "      <td>-0.059560</td>\n",
              "      <td>-0.024641</td>\n",
              "      <td>0.019063</td>\n",
              "      <td>0.019704</td>\n",
              "      <td>-0.017091</td>\n",
              "      <td>0.086157</td>\n",
              "      <td>-0.051860</td>\n",
              "      <td>-0.049499</td>\n",
              "      <td>0.047760</td>\n",
              "      <td>0.135254</td>\n",
              "      <td>-0.011185</td>\n",
              "      <td>0.033549</td>\n",
              "      <td>-0.070093</td>\n",
              "      <td>0.069730</td>\n",
              "      <td>0.052525</td>\n",
              "      <td>0.057918</td>\n",
              "      <td>0.010601</td>\n",
              "      <td>-0.052078</td>\n",
              "      <td>-0.021647</td>\n",
              "      <td>0.028767</td>\n",
              "      <td>0.025027</td>\n",
              "      <td>0.015278</td>\n",
              "      <td>-0.004224</td>\n",
              "      <td>-0.008566</td>\n",
              "      <td>-0.041321</td>\n",
              "      <td>0.024186</td>\n",
              "      <td>0.099360</td>\n",
              "      <td>-0.025270</td>\n",
              "      <td>-0.155365</td>\n",
              "      <td>0.138787</td>\n",
              "      <td>-0.067567</td>\n",
              "      <td>-0.003745</td>\n",
              "      <td>0.004060</td>\n",
              "      <td>0.033323</td>\n",
              "      <td>0.014736</td>\n",
              "      <td>0.095166</td>\n",
              "      <td>0.054628</td>\n",
              "      <td>0.031185</td>\n",
              "      <td>0.027616</td>\n",
              "      <td>0.019930</td>\n",
              "      <td>0.076454</td>\n",
              "      <td>0.018387</td>\n",
              "      <td>0.121566</td>\n",
              "      <td>-0.009655</td>\n",
              "      <td>0.069269</td>\n",
              "      <td>0.064510</td>\n",
              "      <td>0.064865</td>\n",
              "      <td>0.012886</td>\n",
              "      <td>-0.195201</td>\n",
              "      <td>0.046845</td>\n",
              "      <td>-0.014470</td>\n",
              "      <td>-0.087090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.036135</td>\n",
              "      <td>0.060928</td>\n",
              "      <td>-0.045832</td>\n",
              "      <td>-0.021712</td>\n",
              "      <td>0.031051</td>\n",
              "      <td>0.116954</td>\n",
              "      <td>0.093026</td>\n",
              "      <td>-0.027822</td>\n",
              "      <td>0.012752</td>\n",
              "      <td>-0.052951</td>\n",
              "      <td>-0.028258</td>\n",
              "      <td>0.027057</td>\n",
              "      <td>-0.029136</td>\n",
              "      <td>-0.010164</td>\n",
              "      <td>0.012568</td>\n",
              "      <td>0.058478</td>\n",
              "      <td>-0.041214</td>\n",
              "      <td>0.029549</td>\n",
              "      <td>0.005083</td>\n",
              "      <td>0.046028</td>\n",
              "      <td>-0.054956</td>\n",
              "      <td>0.033618</td>\n",
              "      <td>0.018311</td>\n",
              "      <td>0.009927</td>\n",
              "      <td>0.031874</td>\n",
              "      <td>-0.056786</td>\n",
              "      <td>-0.051601</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000993</td>\n",
              "      <td>0.010421</td>\n",
              "      <td>0.060127</td>\n",
              "      <td>0.073892</td>\n",
              "      <td>-0.039378</td>\n",
              "      <td>-0.096642</td>\n",
              "      <td>-0.053912</td>\n",
              "      <td>-0.005296</td>\n",
              "      <td>0.009595</td>\n",
              "      <td>-0.085247</td>\n",
              "      <td>0.063929</td>\n",
              "      <td>-0.021424</td>\n",
              "      <td>0.033577</td>\n",
              "      <td>0.063424</td>\n",
              "      <td>0.032319</td>\n",
              "      <td>-0.137784</td>\n",
              "      <td>0.185954</td>\n",
              "      <td>0.118363</td>\n",
              "      <td>-0.021805</td>\n",
              "      <td>0.015155</td>\n",
              "      <td>-0.061567</td>\n",
              "      <td>0.043021</td>\n",
              "      <td>0.038389</td>\n",
              "      <td>0.051905</td>\n",
              "      <td>0.023407</td>\n",
              "      <td>0.143960</td>\n",
              "      <td>-0.027262</td>\n",
              "      <td>-0.053986</td>\n",
              "      <td>0.063327</td>\n",
              "      <td>0.148148</td>\n",
              "      <td>-0.004690</td>\n",
              "      <td>0.076563</td>\n",
              "      <td>-0.089181</td>\n",
              "      <td>0.008221</td>\n",
              "      <td>0.018480</td>\n",
              "      <td>0.030871</td>\n",
              "      <td>0.054996</td>\n",
              "      <td>-0.073677</td>\n",
              "      <td>0.002084</td>\n",
              "      <td>0.078584</td>\n",
              "      <td>0.069686</td>\n",
              "      <td>0.011664</td>\n",
              "      <td>-0.065486</td>\n",
              "      <td>0.010194</td>\n",
              "      <td>-0.036486</td>\n",
              "      <td>0.005192</td>\n",
              "      <td>0.094966</td>\n",
              "      <td>-0.016059</td>\n",
              "      <td>-0.112567</td>\n",
              "      <td>0.141986</td>\n",
              "      <td>-0.082917</td>\n",
              "      <td>0.005868</td>\n",
              "      <td>-0.000361</td>\n",
              "      <td>0.042258</td>\n",
              "      <td>-0.049653</td>\n",
              "      <td>0.055382</td>\n",
              "      <td>0.110012</td>\n",
              "      <td>0.046045</td>\n",
              "      <td>0.104404</td>\n",
              "      <td>0.020696</td>\n",
              "      <td>0.046833</td>\n",
              "      <td>0.032274</td>\n",
              "      <td>0.042782</td>\n",
              "      <td>-0.007130</td>\n",
              "      <td>0.050428</td>\n",
              "      <td>0.082118</td>\n",
              "      <td>0.107009</td>\n",
              "      <td>-0.042840</td>\n",
              "      <td>-0.190986</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>-0.041266</td>\n",
              "      <td>-0.046468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.039573</td>\n",
              "      <td>0.157933</td>\n",
              "      <td>-0.020214</td>\n",
              "      <td>0.057683</td>\n",
              "      <td>-0.008880</td>\n",
              "      <td>0.104484</td>\n",
              "      <td>-0.052335</td>\n",
              "      <td>0.006033</td>\n",
              "      <td>-0.042691</td>\n",
              "      <td>-0.040424</td>\n",
              "      <td>-0.027922</td>\n",
              "      <td>0.035889</td>\n",
              "      <td>-0.067628</td>\n",
              "      <td>-0.126732</td>\n",
              "      <td>0.004982</td>\n",
              "      <td>0.055914</td>\n",
              "      <td>0.009691</td>\n",
              "      <td>0.024989</td>\n",
              "      <td>-0.048098</td>\n",
              "      <td>-0.005371</td>\n",
              "      <td>0.031314</td>\n",
              "      <td>-0.017267</td>\n",
              "      <td>0.088873</td>\n",
              "      <td>0.019246</td>\n",
              "      <td>0.073914</td>\n",
              "      <td>0.059488</td>\n",
              "      <td>-0.038088</td>\n",
              "      <td>0.017873</td>\n",
              "      <td>0.079816</td>\n",
              "      <td>0.012914</td>\n",
              "      <td>-0.074497</td>\n",
              "      <td>0.059297</td>\n",
              "      <td>-0.089719</td>\n",
              "      <td>-0.137958</td>\n",
              "      <td>0.027465</td>\n",
              "      <td>0.073633</td>\n",
              "      <td>-0.079590</td>\n",
              "      <td>-0.122665</td>\n",
              "      <td>-0.017319</td>\n",
              "      <td>0.060372</td>\n",
              "      <td>-0.049327</td>\n",
              "      <td>0.047486</td>\n",
              "      <td>0.151064</td>\n",
              "      <td>-0.087532</td>\n",
              "      <td>0.150533</td>\n",
              "      <td>0.008041</td>\n",
              "      <td>-0.032695</td>\n",
              "      <td>-0.039066</td>\n",
              "      <td>-0.039877</td>\n",
              "      <td>-0.004224</td>\n",
              "      <td>0.004445</td>\n",
              "      <td>0.010489</td>\n",
              "      <td>0.017666</td>\n",
              "      <td>0.076992</td>\n",
              "      <td>0.009272</td>\n",
              "      <td>-0.014125</td>\n",
              "      <td>0.016549</td>\n",
              "      <td>0.132018</td>\n",
              "      <td>0.003592</td>\n",
              "      <td>0.023962</td>\n",
              "      <td>-0.074207</td>\n",
              "      <td>0.132911</td>\n",
              "      <td>0.088515</td>\n",
              "      <td>0.047677</td>\n",
              "      <td>0.006068</td>\n",
              "      <td>-0.088292</td>\n",
              "      <td>-0.004821</td>\n",
              "      <td>0.026328</td>\n",
              "      <td>0.093638</td>\n",
              "      <td>-0.012713</td>\n",
              "      <td>0.015317</td>\n",
              "      <td>0.032288</td>\n",
              "      <td>0.069446</td>\n",
              "      <td>0.030841</td>\n",
              "      <td>0.060915</td>\n",
              "      <td>-0.061268</td>\n",
              "      <td>-0.057279</td>\n",
              "      <td>0.017419</td>\n",
              "      <td>-0.017211</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.023163</td>\n",
              "      <td>0.076009</td>\n",
              "      <td>0.031592</td>\n",
              "      <td>0.108365</td>\n",
              "      <td>0.053835</td>\n",
              "      <td>-0.027791</td>\n",
              "      <td>0.023800</td>\n",
              "      <td>0.077351</td>\n",
              "      <td>0.054805</td>\n",
              "      <td>-0.054671</td>\n",
              "      <td>0.158273</td>\n",
              "      <td>-0.008926</td>\n",
              "      <td>0.084062</td>\n",
              "      <td>0.036029</td>\n",
              "      <td>0.061134</td>\n",
              "      <td>-0.125965</td>\n",
              "      <td>-0.251415</td>\n",
              "      <td>0.050898</td>\n",
              "      <td>-0.054511</td>\n",
              "      <td>-0.131701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.047127</td>\n",
              "      <td>0.014325</td>\n",
              "      <td>-0.064551</td>\n",
              "      <td>0.083197</td>\n",
              "      <td>-0.019630</td>\n",
              "      <td>0.084514</td>\n",
              "      <td>0.019399</td>\n",
              "      <td>-0.068587</td>\n",
              "      <td>-0.019620</td>\n",
              "      <td>-0.023196</td>\n",
              "      <td>-0.032098</td>\n",
              "      <td>0.042065</td>\n",
              "      <td>-0.044344</td>\n",
              "      <td>-0.004111</td>\n",
              "      <td>0.011791</td>\n",
              "      <td>0.042352</td>\n",
              "      <td>0.012252</td>\n",
              "      <td>-0.014673</td>\n",
              "      <td>0.057341</td>\n",
              "      <td>0.046910</td>\n",
              "      <td>-0.066897</td>\n",
              "      <td>0.064972</td>\n",
              "      <td>-0.034655</td>\n",
              "      <td>0.005188</td>\n",
              "      <td>0.012922</td>\n",
              "      <td>-0.058052</td>\n",
              "      <td>-0.024093</td>\n",
              "      <td>0.065037</td>\n",
              "      <td>0.021435</td>\n",
              "      <td>0.017271</td>\n",
              "      <td>0.063674</td>\n",
              "      <td>0.043773</td>\n",
              "      <td>-0.126437</td>\n",
              "      <td>-0.050208</td>\n",
              "      <td>-0.049604</td>\n",
              "      <td>0.006511</td>\n",
              "      <td>-0.021220</td>\n",
              "      <td>-0.092931</td>\n",
              "      <td>0.030745</td>\n",
              "      <td>-0.063225</td>\n",
              "      <td>-0.003405</td>\n",
              "      <td>0.044456</td>\n",
              "      <td>0.104145</td>\n",
              "      <td>-0.119646</td>\n",
              "      <td>0.159951</td>\n",
              "      <td>0.089902</td>\n",
              "      <td>-0.059345</td>\n",
              "      <td>-0.029951</td>\n",
              "      <td>-0.065419</td>\n",
              "      <td>0.011514</td>\n",
              "      <td>0.012206</td>\n",
              "      <td>0.014106</td>\n",
              "      <td>-0.036344</td>\n",
              "      <td>0.072171</td>\n",
              "      <td>-0.007067</td>\n",
              "      <td>-0.033601</td>\n",
              "      <td>-0.010010</td>\n",
              "      <td>0.109744</td>\n",
              "      <td>-0.005566</td>\n",
              "      <td>0.056769</td>\n",
              "      <td>-0.086494</td>\n",
              "      <td>0.063378</td>\n",
              "      <td>0.043386</td>\n",
              "      <td>0.049098</td>\n",
              "      <td>0.038811</td>\n",
              "      <td>-0.055674</td>\n",
              "      <td>-0.003815</td>\n",
              "      <td>0.037976</td>\n",
              "      <td>0.064653</td>\n",
              "      <td>0.009235</td>\n",
              "      <td>-0.031680</td>\n",
              "      <td>-0.006529</td>\n",
              "      <td>-0.045138</td>\n",
              "      <td>0.014543</td>\n",
              "      <td>0.093950</td>\n",
              "      <td>-0.083166</td>\n",
              "      <td>-0.187691</td>\n",
              "      <td>0.127421</td>\n",
              "      <td>-0.055424</td>\n",
              "      <td>0.015945</td>\n",
              "      <td>-0.037107</td>\n",
              "      <td>0.021291</td>\n",
              "      <td>-0.023526</td>\n",
              "      <td>0.065614</td>\n",
              "      <td>0.030877</td>\n",
              "      <td>0.035494</td>\n",
              "      <td>0.002108</td>\n",
              "      <td>0.014196</td>\n",
              "      <td>0.086827</td>\n",
              "      <td>-0.009053</td>\n",
              "      <td>0.086523</td>\n",
              "      <td>0.025544</td>\n",
              "      <td>0.056027</td>\n",
              "      <td>0.066404</td>\n",
              "      <td>0.042987</td>\n",
              "      <td>0.004231</td>\n",
              "      <td>-0.157346</td>\n",
              "      <td>0.032868</td>\n",
              "      <td>-0.004603</td>\n",
              "      <td>-0.046409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>0.072992</td>\n",
              "      <td>0.061421</td>\n",
              "      <td>-0.072507</td>\n",
              "      <td>0.154582</td>\n",
              "      <td>-0.017961</td>\n",
              "      <td>0.092963</td>\n",
              "      <td>-0.008755</td>\n",
              "      <td>-0.155729</td>\n",
              "      <td>0.010407</td>\n",
              "      <td>-0.039185</td>\n",
              "      <td>0.053642</td>\n",
              "      <td>0.069441</td>\n",
              "      <td>-0.040421</td>\n",
              "      <td>-0.027959</td>\n",
              "      <td>0.023054</td>\n",
              "      <td>0.081762</td>\n",
              "      <td>0.041737</td>\n",
              "      <td>0.031252</td>\n",
              "      <td>-0.027263</td>\n",
              "      <td>0.013952</td>\n",
              "      <td>-0.040392</td>\n",
              "      <td>0.029533</td>\n",
              "      <td>-0.005287</td>\n",
              "      <td>-0.006026</td>\n",
              "      <td>-0.019786</td>\n",
              "      <td>-0.023557</td>\n",
              "      <td>-0.109435</td>\n",
              "      <td>0.077050</td>\n",
              "      <td>0.072039</td>\n",
              "      <td>-0.008176</td>\n",
              "      <td>0.080902</td>\n",
              "      <td>0.116137</td>\n",
              "      <td>-0.140159</td>\n",
              "      <td>-0.140259</td>\n",
              "      <td>-0.027932</td>\n",
              "      <td>0.074213</td>\n",
              "      <td>-0.007709</td>\n",
              "      <td>-0.172199</td>\n",
              "      <td>0.035101</td>\n",
              "      <td>-0.029106</td>\n",
              "      <td>0.017739</td>\n",
              "      <td>0.116714</td>\n",
              "      <td>0.113392</td>\n",
              "      <td>-0.167974</td>\n",
              "      <td>0.171166</td>\n",
              "      <td>0.121920</td>\n",
              "      <td>-0.023881</td>\n",
              "      <td>0.019048</td>\n",
              "      <td>-0.070621</td>\n",
              "      <td>-0.017566</td>\n",
              "      <td>-0.046173</td>\n",
              "      <td>0.009177</td>\n",
              "      <td>0.009068</td>\n",
              "      <td>0.062127</td>\n",
              "      <td>-0.016557</td>\n",
              "      <td>-0.102086</td>\n",
              "      <td>-0.003490</td>\n",
              "      <td>0.070844</td>\n",
              "      <td>-0.050503</td>\n",
              "      <td>0.026266</td>\n",
              "      <td>-0.102985</td>\n",
              "      <td>0.097275</td>\n",
              "      <td>0.027578</td>\n",
              "      <td>0.043907</td>\n",
              "      <td>0.036535</td>\n",
              "      <td>-0.085531</td>\n",
              "      <td>-0.041771</td>\n",
              "      <td>0.021548</td>\n",
              "      <td>0.022069</td>\n",
              "      <td>0.015978</td>\n",
              "      <td>-0.063947</td>\n",
              "      <td>0.002273</td>\n",
              "      <td>-0.044897</td>\n",
              "      <td>0.012826</td>\n",
              "      <td>0.096724</td>\n",
              "      <td>0.010717</td>\n",
              "      <td>-0.154603</td>\n",
              "      <td>0.111576</td>\n",
              "      <td>-0.078541</td>\n",
              "      <td>0.019299</td>\n",
              "      <td>0.019054</td>\n",
              "      <td>0.027277</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>0.019383</td>\n",
              "      <td>0.048016</td>\n",
              "      <td>0.032031</td>\n",
              "      <td>0.007084</td>\n",
              "      <td>0.023381</td>\n",
              "      <td>0.057421</td>\n",
              "      <td>0.028810</td>\n",
              "      <td>0.067925</td>\n",
              "      <td>0.049037</td>\n",
              "      <td>0.054886</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>-0.001977</td>\n",
              "      <td>-0.181355</td>\n",
              "      <td>0.037239</td>\n",
              "      <td>0.069705</td>\n",
              "      <td>-0.079338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>-0.004076</td>\n",
              "      <td>0.051708</td>\n",
              "      <td>-0.037135</td>\n",
              "      <td>0.124179</td>\n",
              "      <td>-0.048005</td>\n",
              "      <td>0.099867</td>\n",
              "      <td>0.029332</td>\n",
              "      <td>-0.094990</td>\n",
              "      <td>-0.027968</td>\n",
              "      <td>-0.030221</td>\n",
              "      <td>0.015495</td>\n",
              "      <td>0.011983</td>\n",
              "      <td>0.001935</td>\n",
              "      <td>-0.068048</td>\n",
              "      <td>0.029728</td>\n",
              "      <td>0.051330</td>\n",
              "      <td>0.033008</td>\n",
              "      <td>-0.001520</td>\n",
              "      <td>0.026196</td>\n",
              "      <td>0.053764</td>\n",
              "      <td>-0.020949</td>\n",
              "      <td>0.046885</td>\n",
              "      <td>-0.009603</td>\n",
              "      <td>0.000946</td>\n",
              "      <td>-0.014247</td>\n",
              "      <td>-0.035876</td>\n",
              "      <td>-0.032827</td>\n",
              "      <td>-0.021135</td>\n",
              "      <td>0.034281</td>\n",
              "      <td>0.036729</td>\n",
              "      <td>0.070477</td>\n",
              "      <td>0.072261</td>\n",
              "      <td>-0.121016</td>\n",
              "      <td>-0.068811</td>\n",
              "      <td>0.002590</td>\n",
              "      <td>0.020815</td>\n",
              "      <td>-0.004962</td>\n",
              "      <td>-0.108317</td>\n",
              "      <td>0.009416</td>\n",
              "      <td>-0.046612</td>\n",
              "      <td>0.018243</td>\n",
              "      <td>0.088364</td>\n",
              "      <td>0.084051</td>\n",
              "      <td>-0.111729</td>\n",
              "      <td>0.146643</td>\n",
              "      <td>0.087691</td>\n",
              "      <td>0.004862</td>\n",
              "      <td>0.021474</td>\n",
              "      <td>-0.054248</td>\n",
              "      <td>0.028745</td>\n",
              "      <td>0.007933</td>\n",
              "      <td>0.035826</td>\n",
              "      <td>-0.007495</td>\n",
              "      <td>0.077300</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>-0.022797</td>\n",
              "      <td>0.041555</td>\n",
              "      <td>0.074839</td>\n",
              "      <td>-0.026332</td>\n",
              "      <td>0.026082</td>\n",
              "      <td>-0.074661</td>\n",
              "      <td>0.090992</td>\n",
              "      <td>0.047141</td>\n",
              "      <td>0.027461</td>\n",
              "      <td>-0.018288</td>\n",
              "      <td>-0.042035</td>\n",
              "      <td>-0.024912</td>\n",
              "      <td>0.023380</td>\n",
              "      <td>0.079701</td>\n",
              "      <td>-0.005610</td>\n",
              "      <td>-0.014284</td>\n",
              "      <td>0.030799</td>\n",
              "      <td>-0.040701</td>\n",
              "      <td>0.012929</td>\n",
              "      <td>0.077573</td>\n",
              "      <td>-0.039890</td>\n",
              "      <td>-0.129100</td>\n",
              "      <td>0.084841</td>\n",
              "      <td>-0.075460</td>\n",
              "      <td>-0.006274</td>\n",
              "      <td>-0.001608</td>\n",
              "      <td>0.017525</td>\n",
              "      <td>0.028175</td>\n",
              "      <td>0.078099</td>\n",
              "      <td>0.035662</td>\n",
              "      <td>0.028442</td>\n",
              "      <td>0.036223</td>\n",
              "      <td>0.021307</td>\n",
              "      <td>0.051086</td>\n",
              "      <td>0.043294</td>\n",
              "      <td>0.105491</td>\n",
              "      <td>0.015424</td>\n",
              "      <td>0.056720</td>\n",
              "      <td>0.019504</td>\n",
              "      <td>0.037504</td>\n",
              "      <td>-0.057102</td>\n",
              "      <td>-0.131954</td>\n",
              "      <td>-0.006964</td>\n",
              "      <td>-0.018257</td>\n",
              "      <td>-0.086776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>-0.018976</td>\n",
              "      <td>-0.020095</td>\n",
              "      <td>-0.068835</td>\n",
              "      <td>0.006007</td>\n",
              "      <td>-0.061755</td>\n",
              "      <td>0.080899</td>\n",
              "      <td>0.010507</td>\n",
              "      <td>-0.131596</td>\n",
              "      <td>0.052080</td>\n",
              "      <td>-0.026943</td>\n",
              "      <td>0.023422</td>\n",
              "      <td>0.000984</td>\n",
              "      <td>-0.045519</td>\n",
              "      <td>0.001027</td>\n",
              "      <td>0.000779</td>\n",
              "      <td>0.005445</td>\n",
              "      <td>0.025026</td>\n",
              "      <td>-0.089514</td>\n",
              "      <td>0.071286</td>\n",
              "      <td>0.044633</td>\n",
              "      <td>-0.055256</td>\n",
              "      <td>0.050054</td>\n",
              "      <td>-0.041321</td>\n",
              "      <td>0.037747</td>\n",
              "      <td>0.022783</td>\n",
              "      <td>-0.101310</td>\n",
              "      <td>0.021628</td>\n",
              "      <td>0.024129</td>\n",
              "      <td>0.060667</td>\n",
              "      <td>0.058565</td>\n",
              "      <td>0.132234</td>\n",
              "      <td>0.047025</td>\n",
              "      <td>-0.137007</td>\n",
              "      <td>-0.083749</td>\n",
              "      <td>0.006757</td>\n",
              "      <td>0.055179</td>\n",
              "      <td>-0.004582</td>\n",
              "      <td>-0.144903</td>\n",
              "      <td>0.012800</td>\n",
              "      <td>-0.072154</td>\n",
              "      <td>0.022564</td>\n",
              "      <td>0.028652</td>\n",
              "      <td>0.091591</td>\n",
              "      <td>-0.110621</td>\n",
              "      <td>0.112952</td>\n",
              "      <td>0.049028</td>\n",
              "      <td>-0.001911</td>\n",
              "      <td>-0.013599</td>\n",
              "      <td>-0.097929</td>\n",
              "      <td>0.013328</td>\n",
              "      <td>-0.004766</td>\n",
              "      <td>0.061360</td>\n",
              "      <td>-0.045369</td>\n",
              "      <td>0.050810</td>\n",
              "      <td>0.022519</td>\n",
              "      <td>-0.033835</td>\n",
              "      <td>0.014947</td>\n",
              "      <td>0.111027</td>\n",
              "      <td>-0.043359</td>\n",
              "      <td>0.100139</td>\n",
              "      <td>-0.034196</td>\n",
              "      <td>0.125882</td>\n",
              "      <td>0.048581</td>\n",
              "      <td>0.060136</td>\n",
              "      <td>0.015841</td>\n",
              "      <td>-0.063894</td>\n",
              "      <td>-0.004671</td>\n",
              "      <td>-0.058153</td>\n",
              "      <td>-0.012682</td>\n",
              "      <td>0.036304</td>\n",
              "      <td>-0.026377</td>\n",
              "      <td>-0.019847</td>\n",
              "      <td>-0.035826</td>\n",
              "      <td>0.024743</td>\n",
              "      <td>0.056156</td>\n",
              "      <td>-0.033316</td>\n",
              "      <td>-0.120117</td>\n",
              "      <td>0.132370</td>\n",
              "      <td>-0.067233</td>\n",
              "      <td>0.010890</td>\n",
              "      <td>-0.020816</td>\n",
              "      <td>0.029969</td>\n",
              "      <td>-0.021405</td>\n",
              "      <td>0.127907</td>\n",
              "      <td>0.042843</td>\n",
              "      <td>0.108523</td>\n",
              "      <td>0.059084</td>\n",
              "      <td>0.056659</td>\n",
              "      <td>0.064342</td>\n",
              "      <td>0.064153</td>\n",
              "      <td>0.060485</td>\n",
              "      <td>-0.024174</td>\n",
              "      <td>0.044688</td>\n",
              "      <td>0.093558</td>\n",
              "      <td>0.074229</td>\n",
              "      <td>-0.028566</td>\n",
              "      <td>-0.178525</td>\n",
              "      <td>0.008641</td>\n",
              "      <td>-0.086734</td>\n",
              "      <td>-0.044515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>0.010251</td>\n",
              "      <td>-0.001374</td>\n",
              "      <td>-0.035312</td>\n",
              "      <td>0.125206</td>\n",
              "      <td>0.022589</td>\n",
              "      <td>0.069817</td>\n",
              "      <td>0.030666</td>\n",
              "      <td>-0.077698</td>\n",
              "      <td>-0.051827</td>\n",
              "      <td>-0.032351</td>\n",
              "      <td>0.023295</td>\n",
              "      <td>0.015860</td>\n",
              "      <td>-0.040329</td>\n",
              "      <td>0.003414</td>\n",
              "      <td>0.035478</td>\n",
              "      <td>0.062868</td>\n",
              "      <td>0.050423</td>\n",
              "      <td>-0.055791</td>\n",
              "      <td>0.011508</td>\n",
              "      <td>0.063100</td>\n",
              "      <td>-0.026569</td>\n",
              "      <td>0.129161</td>\n",
              "      <td>-0.012539</td>\n",
              "      <td>-0.000037</td>\n",
              "      <td>0.021955</td>\n",
              "      <td>-0.062541</td>\n",
              "      <td>-0.031090</td>\n",
              "      <td>-0.008639</td>\n",
              "      <td>0.055509</td>\n",
              "      <td>0.112502</td>\n",
              "      <td>0.051428</td>\n",
              "      <td>0.043963</td>\n",
              "      <td>-0.046321</td>\n",
              "      <td>-0.115241</td>\n",
              "      <td>-0.027452</td>\n",
              "      <td>0.035859</td>\n",
              "      <td>0.052409</td>\n",
              "      <td>-0.081510</td>\n",
              "      <td>-0.056058</td>\n",
              "      <td>-0.015903</td>\n",
              "      <td>0.015892</td>\n",
              "      <td>0.076639</td>\n",
              "      <td>0.029948</td>\n",
              "      <td>-0.058817</td>\n",
              "      <td>0.078486</td>\n",
              "      <td>0.001241</td>\n",
              "      <td>0.009439</td>\n",
              "      <td>0.075545</td>\n",
              "      <td>-0.054919</td>\n",
              "      <td>-0.004066</td>\n",
              "      <td>-0.012697</td>\n",
              "      <td>0.007541</td>\n",
              "      <td>-0.003380</td>\n",
              "      <td>0.014730</td>\n",
              "      <td>0.032084</td>\n",
              "      <td>-0.021433</td>\n",
              "      <td>0.015778</td>\n",
              "      <td>0.045998</td>\n",
              "      <td>0.026132</td>\n",
              "      <td>0.070968</td>\n",
              "      <td>-0.084706</td>\n",
              "      <td>0.034821</td>\n",
              "      <td>0.025479</td>\n",
              "      <td>0.027231</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.059313</td>\n",
              "      <td>-0.014666</td>\n",
              "      <td>-0.013105</td>\n",
              "      <td>0.052927</td>\n",
              "      <td>-0.028899</td>\n",
              "      <td>-0.040568</td>\n",
              "      <td>-0.005057</td>\n",
              "      <td>-0.082594</td>\n",
              "      <td>-0.004659</td>\n",
              "      <td>0.007405</td>\n",
              "      <td>-0.042611</td>\n",
              "      <td>-0.140220</td>\n",
              "      <td>0.092320</td>\n",
              "      <td>-0.019836</td>\n",
              "      <td>-0.017846</td>\n",
              "      <td>-0.077873</td>\n",
              "      <td>0.064523</td>\n",
              "      <td>-0.000938</td>\n",
              "      <td>0.065888</td>\n",
              "      <td>0.053105</td>\n",
              "      <td>0.084587</td>\n",
              "      <td>0.051709</td>\n",
              "      <td>0.134480</td>\n",
              "      <td>0.095011</td>\n",
              "      <td>0.017046</td>\n",
              "      <td>0.116170</td>\n",
              "      <td>0.008665</td>\n",
              "      <td>0.020098</td>\n",
              "      <td>0.124400</td>\n",
              "      <td>0.108705</td>\n",
              "      <td>-0.079640</td>\n",
              "      <td>-0.163437</td>\n",
              "      <td>-0.003368</td>\n",
              "      <td>-0.033252</td>\n",
              "      <td>-0.055717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>0.013563</td>\n",
              "      <td>-0.025963</td>\n",
              "      <td>0.009710</td>\n",
              "      <td>0.028169</td>\n",
              "      <td>0.041949</td>\n",
              "      <td>0.083543</td>\n",
              "      <td>0.075664</td>\n",
              "      <td>-0.079054</td>\n",
              "      <td>0.037926</td>\n",
              "      <td>-0.050204</td>\n",
              "      <td>0.011463</td>\n",
              "      <td>-0.013109</td>\n",
              "      <td>-0.023004</td>\n",
              "      <td>0.021339</td>\n",
              "      <td>0.056742</td>\n",
              "      <td>0.008395</td>\n",
              "      <td>0.015110</td>\n",
              "      <td>-0.066114</td>\n",
              "      <td>-0.016778</td>\n",
              "      <td>0.072633</td>\n",
              "      <td>0.006785</td>\n",
              "      <td>0.087706</td>\n",
              "      <td>-0.037502</td>\n",
              "      <td>-0.023295</td>\n",
              "      <td>0.090429</td>\n",
              "      <td>-0.084435</td>\n",
              "      <td>-0.012697</td>\n",
              "      <td>-0.024931</td>\n",
              "      <td>0.046130</td>\n",
              "      <td>0.037797</td>\n",
              "      <td>0.077470</td>\n",
              "      <td>-0.006906</td>\n",
              "      <td>-0.050395</td>\n",
              "      <td>-0.038791</td>\n",
              "      <td>0.012849</td>\n",
              "      <td>0.046453</td>\n",
              "      <td>-0.009180</td>\n",
              "      <td>-0.068815</td>\n",
              "      <td>0.057218</td>\n",
              "      <td>-0.084335</td>\n",
              "      <td>0.044424</td>\n",
              "      <td>0.011188</td>\n",
              "      <td>0.106886</td>\n",
              "      <td>-0.104599</td>\n",
              "      <td>0.125092</td>\n",
              "      <td>0.031500</td>\n",
              "      <td>-0.025811</td>\n",
              "      <td>0.010058</td>\n",
              "      <td>-0.053882</td>\n",
              "      <td>-0.024123</td>\n",
              "      <td>0.101485</td>\n",
              "      <td>-0.047887</td>\n",
              "      <td>-0.041693</td>\n",
              "      <td>0.086543</td>\n",
              "      <td>0.027810</td>\n",
              "      <td>0.001143</td>\n",
              "      <td>0.097247</td>\n",
              "      <td>0.181952</td>\n",
              "      <td>0.022860</td>\n",
              "      <td>0.061727</td>\n",
              "      <td>-0.112615</td>\n",
              "      <td>0.052403</td>\n",
              "      <td>0.046491</td>\n",
              "      <td>0.046958</td>\n",
              "      <td>-0.013483</td>\n",
              "      <td>-0.005858</td>\n",
              "      <td>-0.024977</td>\n",
              "      <td>0.021847</td>\n",
              "      <td>0.072617</td>\n",
              "      <td>0.042761</td>\n",
              "      <td>-0.027840</td>\n",
              "      <td>-0.015910</td>\n",
              "      <td>-0.056350</td>\n",
              "      <td>0.013601</td>\n",
              "      <td>0.050274</td>\n",
              "      <td>-0.062096</td>\n",
              "      <td>-0.115606</td>\n",
              "      <td>0.168057</td>\n",
              "      <td>-0.082203</td>\n",
              "      <td>-0.003536</td>\n",
              "      <td>-0.011414</td>\n",
              "      <td>0.036543</td>\n",
              "      <td>-0.030944</td>\n",
              "      <td>0.129950</td>\n",
              "      <td>0.069226</td>\n",
              "      <td>-0.006946</td>\n",
              "      <td>-0.010859</td>\n",
              "      <td>0.057215</td>\n",
              "      <td>0.097694</td>\n",
              "      <td>0.007187</td>\n",
              "      <td>0.115082</td>\n",
              "      <td>-0.064792</td>\n",
              "      <td>0.112246</td>\n",
              "      <td>0.066730</td>\n",
              "      <td>0.032176</td>\n",
              "      <td>-0.057578</td>\n",
              "      <td>-0.197998</td>\n",
              "      <td>-0.049758</td>\n",
              "      <td>-0.055783</td>\n",
              "      <td>-0.138811</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4         5         6   \\\n",
              "0      0.044147 -0.010727 -0.021333  0.073693 -0.021842  0.106237  0.048300   \n",
              "1      0.045035  0.015012 -0.031230  0.095337 -0.005714  0.072040  0.021957   \n",
              "2      0.036135  0.060928 -0.045832 -0.021712  0.031051  0.116954  0.093026   \n",
              "3      0.039573  0.157933 -0.020214  0.057683 -0.008880  0.104484 -0.052335   \n",
              "4      0.047127  0.014325 -0.064551  0.083197 -0.019630  0.084514  0.019399   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995  0.072992  0.061421 -0.072507  0.154582 -0.017961  0.092963 -0.008755   \n",
              "49996 -0.004076  0.051708 -0.037135  0.124179 -0.048005  0.099867  0.029332   \n",
              "49997 -0.018976 -0.020095 -0.068835  0.006007 -0.061755  0.080899  0.010507   \n",
              "49998  0.010251 -0.001374 -0.035312  0.125206  0.022589  0.069817  0.030666   \n",
              "49999  0.013563 -0.025963  0.009710  0.028169  0.041949  0.083543  0.075664   \n",
              "\n",
              "             7         8         9         10        11        12        13  \\\n",
              "0     -0.033911 -0.003105 -0.029260 -0.017412  0.018268 -0.012076  0.004286   \n",
              "1     -0.104118 -0.012181 -0.034687 -0.009410  0.018831 -0.037818 -0.007835   \n",
              "2     -0.027822  0.012752 -0.052951 -0.028258  0.027057 -0.029136 -0.010164   \n",
              "3      0.006033 -0.042691 -0.040424 -0.027922  0.035889 -0.067628 -0.126732   \n",
              "4     -0.068587 -0.019620 -0.023196 -0.032098  0.042065 -0.044344 -0.004111   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995 -0.155729  0.010407 -0.039185  0.053642  0.069441 -0.040421 -0.027959   \n",
              "49996 -0.094990 -0.027968 -0.030221  0.015495  0.011983  0.001935 -0.068048   \n",
              "49997 -0.131596  0.052080 -0.026943  0.023422  0.000984 -0.045519  0.001027   \n",
              "49998 -0.077698 -0.051827 -0.032351  0.023295  0.015860 -0.040329  0.003414   \n",
              "49999 -0.079054  0.037926 -0.050204  0.011463 -0.013109 -0.023004  0.021339   \n",
              "\n",
              "             14        15        16        17        18        19        20  \\\n",
              "0      0.062145  0.006855  0.022881 -0.024971  0.006245  0.002184 -0.071574   \n",
              "1      0.026300  0.040378  0.045364 -0.009003  0.017358  0.044997 -0.033400   \n",
              "2      0.012568  0.058478 -0.041214  0.029549  0.005083  0.046028 -0.054956   \n",
              "3      0.004982  0.055914  0.009691  0.024989 -0.048098 -0.005371  0.031314   \n",
              "4      0.011791  0.042352  0.012252 -0.014673  0.057341  0.046910 -0.066897   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995  0.023054  0.081762  0.041737  0.031252 -0.027263  0.013952 -0.040392   \n",
              "49996  0.029728  0.051330  0.033008 -0.001520  0.026196  0.053764 -0.020949   \n",
              "49997  0.000779  0.005445  0.025026 -0.089514  0.071286  0.044633 -0.055256   \n",
              "49998  0.035478  0.062868  0.050423 -0.055791  0.011508  0.063100 -0.026569   \n",
              "49999  0.056742  0.008395  0.015110 -0.066114 -0.016778  0.072633  0.006785   \n",
              "\n",
              "             21        22        23        24        25        26        27  \\\n",
              "0      0.051942 -0.000050  0.017572  0.010189 -0.026628 -0.092220  0.018010   \n",
              "1      0.055305 -0.014680  0.035894  0.005406 -0.064536 -0.022109  0.004644   \n",
              "2      0.033618  0.018311  0.009927  0.031874 -0.056786 -0.051601  0.000337   \n",
              "3     -0.017267  0.088873  0.019246  0.073914  0.059488 -0.038088  0.017873   \n",
              "4      0.064972 -0.034655  0.005188  0.012922 -0.058052 -0.024093  0.065037   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995  0.029533 -0.005287 -0.006026 -0.019786 -0.023557 -0.109435  0.077050   \n",
              "49996  0.046885 -0.009603  0.000946 -0.014247 -0.035876 -0.032827 -0.021135   \n",
              "49997  0.050054 -0.041321  0.037747  0.022783 -0.101310  0.021628  0.024129   \n",
              "49998  0.129161 -0.012539 -0.000037  0.021955 -0.062541 -0.031090 -0.008639   \n",
              "49999  0.087706 -0.037502 -0.023295  0.090429 -0.084435 -0.012697 -0.024931   \n",
              "\n",
              "             28        29        30        31        32        33        34  \\\n",
              "0      0.074499  0.021300  0.075879  0.048802 -0.143237 -0.148499 -0.035969   \n",
              "1      0.065064 -0.003331  0.078107  0.064094 -0.087262 -0.071299 -0.013654   \n",
              "2      0.000993  0.010421  0.060127  0.073892 -0.039378 -0.096642 -0.053912   \n",
              "3      0.079816  0.012914 -0.074497  0.059297 -0.089719 -0.137958  0.027465   \n",
              "4      0.021435  0.017271  0.063674  0.043773 -0.126437 -0.050208 -0.049604   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995  0.072039 -0.008176  0.080902  0.116137 -0.140159 -0.140259 -0.027932   \n",
              "49996  0.034281  0.036729  0.070477  0.072261 -0.121016 -0.068811  0.002590   \n",
              "49997  0.060667  0.058565  0.132234  0.047025 -0.137007 -0.083749  0.006757   \n",
              "49998  0.055509  0.112502  0.051428  0.043963 -0.046321 -0.115241 -0.027452   \n",
              "49999  0.046130  0.037797  0.077470 -0.006906 -0.050395 -0.038791  0.012849   \n",
              "\n",
              "             35        36        37        38        39        40        41  \\\n",
              "0      0.028878 -0.059840 -0.137513  0.002799 -0.057196 -0.001409  0.055020   \n",
              "1      0.003943  0.009838 -0.122297  0.017988 -0.051111  0.042570  0.038836   \n",
              "2     -0.005296  0.009595 -0.085247  0.063929 -0.021424  0.033577  0.063424   \n",
              "3      0.073633 -0.079590 -0.122665 -0.017319  0.060372 -0.049327  0.047486   \n",
              "4      0.006511 -0.021220 -0.092931  0.030745 -0.063225 -0.003405  0.044456   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995  0.074213 -0.007709 -0.172199  0.035101 -0.029106  0.017739  0.116714   \n",
              "49996  0.020815 -0.004962 -0.108317  0.009416 -0.046612  0.018243  0.088364   \n",
              "49997  0.055179 -0.004582 -0.144903  0.012800 -0.072154  0.022564  0.028652   \n",
              "49998  0.035859  0.052409 -0.081510 -0.056058 -0.015903  0.015892  0.076639   \n",
              "49999  0.046453 -0.009180 -0.068815  0.057218 -0.084335  0.044424  0.011188   \n",
              "\n",
              "             42        43        44        45        46        47        48  \\\n",
              "0      0.102742 -0.117058  0.157518  0.094997 -0.007800  0.034279 -0.063406   \n",
              "1      0.092849 -0.126283  0.115054  0.119809 -0.031324 -0.015771 -0.059560   \n",
              "2      0.032319 -0.137784  0.185954  0.118363 -0.021805  0.015155 -0.061567   \n",
              "3      0.151064 -0.087532  0.150533  0.008041 -0.032695 -0.039066 -0.039877   \n",
              "4      0.104145 -0.119646  0.159951  0.089902 -0.059345 -0.029951 -0.065419   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995  0.113392 -0.167974  0.171166  0.121920 -0.023881  0.019048 -0.070621   \n",
              "49996  0.084051 -0.111729  0.146643  0.087691  0.004862  0.021474 -0.054248   \n",
              "49997  0.091591 -0.110621  0.112952  0.049028 -0.001911 -0.013599 -0.097929   \n",
              "49998  0.029948 -0.058817  0.078486  0.001241  0.009439  0.075545 -0.054919   \n",
              "49999  0.106886 -0.104599  0.125092  0.031500 -0.025811  0.010058 -0.053882   \n",
              "\n",
              "             49        50        51        52        53        54        55  \\\n",
              "0     -0.064017 -0.016375  0.014664 -0.050131  0.099417 -0.006343 -0.066297   \n",
              "1     -0.024641  0.019063  0.019704 -0.017091  0.086157 -0.051860 -0.049499   \n",
              "2      0.043021  0.038389  0.051905  0.023407  0.143960 -0.027262 -0.053986   \n",
              "3     -0.004224  0.004445  0.010489  0.017666  0.076992  0.009272 -0.014125   \n",
              "4      0.011514  0.012206  0.014106 -0.036344  0.072171 -0.007067 -0.033601   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995 -0.017566 -0.046173  0.009177  0.009068  0.062127 -0.016557 -0.102086   \n",
              "49996  0.028745  0.007933  0.035826 -0.007495  0.077300  0.029120 -0.022797   \n",
              "49997  0.013328 -0.004766  0.061360 -0.045369  0.050810  0.022519 -0.033835   \n",
              "49998 -0.004066 -0.012697  0.007541 -0.003380  0.014730  0.032084 -0.021433   \n",
              "49999 -0.024123  0.101485 -0.047887 -0.041693  0.086543  0.027810  0.001143   \n",
              "\n",
              "             56        57        58        59        60        61        62  \\\n",
              "0      0.051177  0.183496 -0.063202  0.009117 -0.053415  0.044517  0.013730   \n",
              "1      0.047760  0.135254 -0.011185  0.033549 -0.070093  0.069730  0.052525   \n",
              "2      0.063327  0.148148 -0.004690  0.076563 -0.089181  0.008221  0.018480   \n",
              "3      0.016549  0.132018  0.003592  0.023962 -0.074207  0.132911  0.088515   \n",
              "4     -0.010010  0.109744 -0.005566  0.056769 -0.086494  0.063378  0.043386   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995 -0.003490  0.070844 -0.050503  0.026266 -0.102985  0.097275  0.027578   \n",
              "49996  0.041555  0.074839 -0.026332  0.026082 -0.074661  0.090992  0.047141   \n",
              "49997  0.014947  0.111027 -0.043359  0.100139 -0.034196  0.125882  0.048581   \n",
              "49998  0.015778  0.045998  0.026132  0.070968 -0.084706  0.034821  0.025479   \n",
              "49999  0.097247  0.181952  0.022860  0.061727 -0.112615  0.052403  0.046491   \n",
              "\n",
              "             63        64        65        66        67        68        69  \\\n",
              "0      0.011338  0.013443 -0.104968  0.002170  0.009175  0.074044  0.016404   \n",
              "1      0.057918  0.010601 -0.052078 -0.021647  0.028767  0.025027  0.015278   \n",
              "2      0.030871  0.054996 -0.073677  0.002084  0.078584  0.069686  0.011664   \n",
              "3      0.047677  0.006068 -0.088292 -0.004821  0.026328  0.093638 -0.012713   \n",
              "4      0.049098  0.038811 -0.055674 -0.003815  0.037976  0.064653  0.009235   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995  0.043907  0.036535 -0.085531 -0.041771  0.021548  0.022069  0.015978   \n",
              "49996  0.027461 -0.018288 -0.042035 -0.024912  0.023380  0.079701 -0.005610   \n",
              "49997  0.060136  0.015841 -0.063894 -0.004671 -0.058153 -0.012682  0.036304   \n",
              "49998  0.027231  0.000708  0.059313 -0.014666 -0.013105  0.052927 -0.028899   \n",
              "49999  0.046958 -0.013483 -0.005858 -0.024977  0.021847  0.072617  0.042761   \n",
              "\n",
              "             70        71        72        73        74        75        76  \\\n",
              "0      0.009218 -0.003867  0.013765  0.056818  0.130176 -0.050709 -0.108570   \n",
              "1     -0.004224 -0.008566 -0.041321  0.024186  0.099360 -0.025270 -0.155365   \n",
              "2     -0.065486  0.010194 -0.036486  0.005192  0.094966 -0.016059 -0.112567   \n",
              "3      0.015317  0.032288  0.069446  0.030841  0.060915 -0.061268 -0.057279   \n",
              "4     -0.031680 -0.006529 -0.045138  0.014543  0.093950 -0.083166 -0.187691   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995 -0.063947  0.002273 -0.044897  0.012826  0.096724  0.010717 -0.154603   \n",
              "49996 -0.014284  0.030799 -0.040701  0.012929  0.077573 -0.039890 -0.129100   \n",
              "49997 -0.026377 -0.019847 -0.035826  0.024743  0.056156 -0.033316 -0.120117   \n",
              "49998 -0.040568 -0.005057 -0.082594 -0.004659  0.007405 -0.042611 -0.140220   \n",
              "49999 -0.027840 -0.015910 -0.056350  0.013601  0.050274 -0.062096 -0.115606   \n",
              "\n",
              "             77        78        79        80        81        82        83  \\\n",
              "0      0.132067 -0.052417 -0.002704  0.084048  0.018089  0.015692  0.109482   \n",
              "1      0.138787 -0.067567 -0.003745  0.004060  0.033323  0.014736  0.095166   \n",
              "2      0.141986 -0.082917  0.005868 -0.000361  0.042258 -0.049653  0.055382   \n",
              "3      0.017419 -0.017211 -0.024124 -0.023163  0.076009  0.031592  0.108365   \n",
              "4      0.127421 -0.055424  0.015945 -0.037107  0.021291 -0.023526  0.065614   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995  0.111576 -0.078541  0.019299  0.019054  0.027277  0.004200  0.019383   \n",
              "49996  0.084841 -0.075460 -0.006274 -0.001608  0.017525  0.028175  0.078099   \n",
              "49997  0.132370 -0.067233  0.010890 -0.020816  0.029969 -0.021405  0.127907   \n",
              "49998  0.092320 -0.019836 -0.017846 -0.077873  0.064523 -0.000938  0.065888   \n",
              "49999  0.168057 -0.082203 -0.003536 -0.011414  0.036543 -0.030944  0.129950   \n",
              "\n",
              "             84        85        86        87        88        89        90  \\\n",
              "0      0.058689  0.019810  0.011112  0.046629  0.097933  0.038506  0.144735   \n",
              "1      0.054628  0.031185  0.027616  0.019930  0.076454  0.018387  0.121566   \n",
              "2      0.110012  0.046045  0.104404  0.020696  0.046833  0.032274  0.042782   \n",
              "3      0.053835 -0.027791  0.023800  0.077351  0.054805 -0.054671  0.158273   \n",
              "4      0.030877  0.035494  0.002108  0.014196  0.086827 -0.009053  0.086523   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995  0.048016  0.032031  0.007084  0.023381  0.057421  0.028810  0.067925   \n",
              "49996  0.035662  0.028442  0.036223  0.021307  0.051086  0.043294  0.105491   \n",
              "49997  0.042843  0.108523  0.059084  0.056659  0.064342  0.064153  0.060485   \n",
              "49998  0.053105  0.084587  0.051709  0.134480  0.095011  0.017046  0.116170   \n",
              "49999  0.069226 -0.006946 -0.010859  0.057215  0.097694  0.007187  0.115082   \n",
              "\n",
              "             91        92        93        94        95        96        97  \\\n",
              "0      0.017034  0.050863  0.090643  0.037196 -0.060164 -0.204394  0.036898   \n",
              "1     -0.009655  0.069269  0.064510  0.064865  0.012886 -0.195201  0.046845   \n",
              "2     -0.007130  0.050428  0.082118  0.107009 -0.042840 -0.190986 -0.000122   \n",
              "3     -0.008926  0.084062  0.036029  0.061134 -0.125965 -0.251415  0.050898   \n",
              "4      0.025544  0.056027  0.066404  0.042987  0.004231 -0.157346  0.032868   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "49995  0.049037  0.054886  0.022692  0.003686 -0.001977 -0.181355  0.037239   \n",
              "49996  0.015424  0.056720  0.019504  0.037504 -0.057102 -0.131954 -0.006964   \n",
              "49997 -0.024174  0.044688  0.093558  0.074229 -0.028566 -0.178525  0.008641   \n",
              "49998  0.008665  0.020098  0.124400  0.108705 -0.079640 -0.163437 -0.003368   \n",
              "49999 -0.064792  0.112246  0.066730  0.032176 -0.057578 -0.197998 -0.049758   \n",
              "\n",
              "             98        99  \n",
              "0      0.005015 -0.080517  \n",
              "1     -0.014470 -0.087090  \n",
              "2     -0.041266 -0.046468  \n",
              "3     -0.054511 -0.131701  \n",
              "4     -0.004603 -0.046409  \n",
              "...         ...       ...  \n",
              "49995  0.069705 -0.079338  \n",
              "49996 -0.018257 -0.086776  \n",
              "49997 -0.086734 -0.044515  \n",
              "49998 -0.033252 -0.055717  \n",
              "49999 -0.055783 -0.138811  \n",
              "\n",
              "[50000 rows x 100 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# If smaller sample: Convert vector string in csv file to df\n",
        "# and cast all cols as float. This takes ~50 min for the full 360,000 rows.\n",
        "# --> If full data: Load pickle file to save time.\n",
        "\n",
        "if sample_size != None:\n",
        "    corp_ft = df['ft_vector'].str.strip('[]').str.split(expand=True)\n",
        "    corp_ft = corp_ft.astype('float')\n",
        "    display(corp_ft)\n",
        "    # with open('pickle/ft_vectors.pkl', mode='wb') as f:\n",
        "    #     pickle.dump(corp_ft, f)\n",
        "\n",
        "else:\n",
        "    with open('pickle/ft_vectors.pkl', mode='rb') as f:\n",
        "        corp_ft = pickle.load(f)\n",
        "    display(corp_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of words on raw comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<50000x56064 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1911230 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect_bow = CountVectorizer()\n",
        "corp_raw_bow = vect_bow.fit_transform(corp_raw)\n",
        "corp_raw_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of words on cleaned comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<50000x52776 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1895064 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corp_bow = vect_bow.fit_transform(corp_clean)\n",
        "corp_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of words  on preprocessed comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<50000x43778 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1022041 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corp_pp_bow = vect_bow.fit_transform(corp_pp)\n",
        "corp_pp_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of 1/2-grams on preprocessed comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<50000x807794 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 2116644 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect_bo12grams = CountVectorizer(ngram_range=(1,2))\n",
        "corp_pp_bo12grams = vect_bo12grams.fit_transform(corp_pp)\n",
        "corp_pp_bo12grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tf_idf on cleaned comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<50000x52776 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1895064 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect_tfidf = TfidfVectorizer()\n",
        "corp_tfidf = vect_tfidf.fit_transform(corp_clean)\n",
        "corp_tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tf_idf on preprocessed comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<50000x43778 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1022041 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect_tfidf = TfidfVectorizer()\n",
        "corp_pp_tfidf = vect_tfidf.fit_transform(corp_pp)\n",
        "corp_pp_tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline model (logistic regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'max_iter': 2_000}\n",
        "\n",
        "# load model with parameters\n",
        "lr = LogisticRegression(**params)\n",
        "\n",
        "test_result = test_model(lr, 'BASELINE (logistic regression)', params,\n",
        "                    'bag of words on raw comments', corp_raw_bow, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XGBoost experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'bag of words (cleaned)',\n",
        "                         corp_bow, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'bag of words (preprocessed)',\n",
        "                         corp_pp_bow, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params,\n",
        "                         'bag of 1/2-grams (preprocessed)',\n",
        "                         corp_pp_bo12grams, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'tf_idf',\n",
        "                         corp_tfidf, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'tf_idf (preprocessed)',\n",
        "                         corp_pp_tfidf, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1,\n",
        "          'n_estimators': 1000}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'tf_idf (preprocessed)',\n",
        "                         corp_pp_tfidf, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2b5q-TtHlGq",
        "outputId": "2aa1220d-5ebf-47f0-888d-3ccbf7b1f1b2"
      },
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'fastText vectors',\n",
        "                         corp_ft, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1,\n",
        "          'n_estimators': 1000}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'fastText vectors',\n",
        "                         corp_ft, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show test results + total exec time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>model_params</th>\n",
              "      <th>data_desc</th>\n",
              "      <th>data_size</th>\n",
              "      <th>features_no</th>\n",
              "      <th>f1</th>\n",
              "      <th>acc</th>\n",
              "      <th>recall</th>\n",
              "      <th>prec</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>cf_matrix</th>\n",
              "      <th>train_time</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BASELINE (logistic regression)</td>\n",
              "      <td>{'max_iter': 2000}</td>\n",
              "      <td>bag of words on raw comments</td>\n",
              "      <td>50000</td>\n",
              "      <td>56064</td>\n",
              "      <td>0.795</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.848</td>\n",
              "      <td>0.901</td>\n",
              "      <td>[[6827, 673], [1255, 3745]]</td>\n",
              "      <td>0m 4s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>{'random_state': 42, 'n_jobs': -1}</td>\n",
              "      <td>bag of words (cleaned)</td>\n",
              "      <td>50000</td>\n",
              "      <td>52776</td>\n",
              "      <td>0.766</td>\n",
              "      <td>0.834</td>\n",
              "      <td>0.679</td>\n",
              "      <td>0.879</td>\n",
              "      <td>0.900</td>\n",
              "      <td>[[7034, 466], [1605, 3395]]</td>\n",
              "      <td>0m 2s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>{'random_state': 42, 'n_jobs': -1}</td>\n",
              "      <td>bag of words (preprocessed)</td>\n",
              "      <td>50000</td>\n",
              "      <td>43778</td>\n",
              "      <td>0.766</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.683</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.906</td>\n",
              "      <td>[[6996, 504], [1587, 3413]]</td>\n",
              "      <td>0m 1s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>{'random_state': 42, 'n_jobs': -1}</td>\n",
              "      <td>bag of 1/2-grams (preprocessed)</td>\n",
              "      <td>50000</td>\n",
              "      <td>807794</td>\n",
              "      <td>0.765</td>\n",
              "      <td>0.832</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.873</td>\n",
              "      <td>0.905</td>\n",
              "      <td>[[7003, 497], [1598, 3402]]</td>\n",
              "      <td>0m 13s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>{'random_state': 42, 'n_jobs': -1}</td>\n",
              "      <td>tf_idf</td>\n",
              "      <td>50000</td>\n",
              "      <td>52776</td>\n",
              "      <td>0.771</td>\n",
              "      <td>0.837</td>\n",
              "      <td>0.684</td>\n",
              "      <td>0.883</td>\n",
              "      <td>0.900</td>\n",
              "      <td>[[7046, 454], [1578, 3422]]</td>\n",
              "      <td>0m 9s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>{'random_state': 42, 'n_jobs': -1}</td>\n",
              "      <td>tf_idf (preprocessed)</td>\n",
              "      <td>50000</td>\n",
              "      <td>43778</td>\n",
              "      <td>0.774</td>\n",
              "      <td>0.837</td>\n",
              "      <td>0.698</td>\n",
              "      <td>0.869</td>\n",
              "      <td>0.904</td>\n",
              "      <td>[[6976, 524], [1510, 3490]]</td>\n",
              "      <td>0m 7s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>{'random_state': 42, 'n_jobs': -1, 'n_estimato...</td>\n",
              "      <td>tf_idf (preprocessed)</td>\n",
              "      <td>50000</td>\n",
              "      <td>43778</td>\n",
              "      <td>0.809</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.768</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.922</td>\n",
              "      <td>[[6844, 656], [1159, 3841]]</td>\n",
              "      <td>0m 56s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>{'random_state': 42, 'n_jobs': -1}</td>\n",
              "      <td>fastText vectors</td>\n",
              "      <td>50000</td>\n",
              "      <td>100</td>\n",
              "      <td>0.705</td>\n",
              "      <td>0.773</td>\n",
              "      <td>0.676</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.846</td>\n",
              "      <td>[[6283, 1217], [1618, 3382]]</td>\n",
              "      <td>0m 1s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>{'random_state': 42, 'n_jobs': -1, 'n_estimato...</td>\n",
              "      <td>fastText vectors</td>\n",
              "      <td>50000</td>\n",
              "      <td>100</td>\n",
              "      <td>0.716</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.694</td>\n",
              "      <td>0.739</td>\n",
              "      <td>0.854</td>\n",
              "      <td>[[6274, 1226], [1530, 3470]]</td>\n",
              "      <td>0m 11s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       model_name  \\\n",
              "0  BASELINE (logistic regression)   \n",
              "1                         XGBoost   \n",
              "2                         XGBoost   \n",
              "3                         XGBoost   \n",
              "4                         XGBoost   \n",
              "5                         XGBoost   \n",
              "6                         XGBoost   \n",
              "7                         XGBoost   \n",
              "8                         XGBoost   \n",
              "\n",
              "                                        model_params  \\\n",
              "0                                 {'max_iter': 2000}   \n",
              "1                 {'random_state': 42, 'n_jobs': -1}   \n",
              "2                 {'random_state': 42, 'n_jobs': -1}   \n",
              "3                 {'random_state': 42, 'n_jobs': -1}   \n",
              "4                 {'random_state': 42, 'n_jobs': -1}   \n",
              "5                 {'random_state': 42, 'n_jobs': -1}   \n",
              "6  {'random_state': 42, 'n_jobs': -1, 'n_estimato...   \n",
              "7                 {'random_state': 42, 'n_jobs': -1}   \n",
              "8  {'random_state': 42, 'n_jobs': -1, 'n_estimato...   \n",
              "\n",
              "                         data_desc  data_size  features_no     f1    acc  \\\n",
              "0     bag of words on raw comments      50000        56064  0.795  0.846   \n",
              "1           bag of words (cleaned)      50000        52776  0.766  0.834   \n",
              "2      bag of words (preprocessed)      50000        43778  0.766  0.833   \n",
              "3  bag of 1/2-grams (preprocessed)      50000       807794  0.765  0.832   \n",
              "4                           tf_idf      50000        52776  0.771  0.837   \n",
              "5            tf_idf (preprocessed)      50000        43778  0.774  0.837   \n",
              "6            tf_idf (preprocessed)      50000        43778  0.809  0.855   \n",
              "7                 fastText vectors      50000          100  0.705  0.773   \n",
              "8                 fastText vectors      50000          100  0.716  0.780   \n",
              "\n",
              "   recall   prec  roc_auc                     cf_matrix train_time notes  \n",
              "0   0.749  0.848    0.901   [[6827, 673], [1255, 3745]]      0m 4s        \n",
              "1   0.679  0.879    0.900   [[7034, 466], [1605, 3395]]      0m 2s        \n",
              "2   0.683  0.871    0.906   [[6996, 504], [1587, 3413]]      0m 1s        \n",
              "3   0.680  0.873    0.905   [[7003, 497], [1598, 3402]]     0m 13s        \n",
              "4   0.684  0.883    0.900   [[7046, 454], [1578, 3422]]      0m 9s        \n",
              "5   0.698  0.869    0.904   [[6976, 524], [1510, 3490]]      0m 7s        \n",
              "6   0.768  0.854    0.922   [[6844, 656], [1159, 3841]]     0m 56s        \n",
              "7   0.676  0.735    0.846  [[6283, 1217], [1618, 3382]]      0m 1s        \n",
              "8   0.694  0.739    0.854  [[6274, 1226], [1530, 3470]]     0m 11s        "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full run time: 2m 34s\n"
          ]
        }
      ],
      "source": [
        "full_run_time = time.time() - full_run_time_start\n",
        "print(f'Full run time: {int(full_run_time // 60)}m {round(full_run_time % 60)}s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate average comment length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average comment length:\n",
            "291 characters\n",
            "51 words\n"
          ]
        }
      ],
      "source": [
        "# characters\n",
        "comm_len_chars = df['comment_clean'].apply(lambda s: len(s))\n",
        "avg_comm_len_chars = comm_len_chars.sum() / len(comm_len_chars)\n",
        "\n",
        "# words (rough count)\n",
        "comm_len_words = df['comment_clean']\\\n",
        "    .apply(lambda s: len(re.findall(r'\\S+', s)))\n",
        "avg_comm_len_words = comm_len_words.sum() / len(comm_len_words)\n",
        "\n",
        "print('Average comment length:')\n",
        "print(round(avg_comm_len_chars), 'characters')\n",
        "print(round(avg_comm_len_words), 'words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
